{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Member_number', 'Date', 'itemDescription'], dtype='object')\n",
      "Frequent itemsets found: 165\n",
      "No association rules found with the specified confidence threshold.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- 1. Load the dataset ----\n",
    "df = pd.read_csv('GroceriesDataset.csv')\n",
    "\n",
    "# ---- 2. Inspect the dataset to check column names ----\n",
    "print(df.columns)  # Print column names to identify the correct structure\n",
    "\n",
    "# ---- 3. Preprocess the data ----\n",
    "# Group by Member_number and aggregate item descriptions into lists for each member\n",
    "transactions = df.groupby('Member_number')['itemDescription'].apply(list).values.tolist()\n",
    "\n",
    "# ---- 4. Use TransactionEncoder to convert the list of transactions ----\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_transformed = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# ---- 5. Apply the Apriori Algorithm ----\n",
    "# Use a lower min_support threshold\n",
    "min_support = 0.05  # Set support to 5%, can be adjusted based on the data\n",
    "frequent_itemsets = apriori(df_transformed, min_support=min_support, use_colnames=True)\n",
    "\n",
    "# Check if frequent itemsets were found\n",
    "if frequent_itemsets.empty:\n",
    "    print(\"No frequent itemsets found with the specified min_support threshold.\")\n",
    "else:\n",
    "    print(f\"Frequent itemsets found: {len(frequent_itemsets)}\")\n",
    "\n",
    "# Generate association rules with a minimum confidence of 0.7\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# Check if any rules were generated\n",
    "if rules.empty:\n",
    "    print(\"No association rules found with the specified confidence threshold.\")\n",
    "else:\n",
    "    print(f\"Association rules found: {len(rules)}\")\n",
    "\n",
    "# ---- 6. Visualize Results using a Network Graph (only if rules are found) ----\n",
    "if not rules.empty:\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes and edges based on the rules\n",
    "    for index, rule in rules.iterrows():\n",
    "        # Each edge is an association rule: from 'antecedents' to 'consequents'\n",
    "        G.add_edge(tuple(rule['antecedents'])[0], tuple(rule['consequents'])[0], weight=rule['confidence'])\n",
    "\n",
    "    # Draw the network graph\n",
    "    pos = nx.spring_layout(G)  # Layout for nodes\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    nx.draw(G, pos, with_labels=True, node_size=3000, node_color='skyblue', font_size=12, font_weight='bold', width=2, alpha=0.7)\n",
    "    plt.title(\"Association Rules Network\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
